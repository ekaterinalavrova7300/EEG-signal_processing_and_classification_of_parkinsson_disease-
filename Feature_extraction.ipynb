{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b336a3f6-6fc3-47f6-911a-544e07705373",
   "metadata": {},
   "source": [
    "# Classification of Parkinsson patients from EEG signals #\n",
    "Ekaterina Lavrova "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a93239-592a-4526-b7ae-38ad2edbd76d",
   "metadata": {},
   "source": [
    "## Import Packages ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254b2bf-2290-45f0-8a33-c1a78bfc53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import mne \n",
    "from mne.preprocessing import ICA\n",
    "from scipy.signal import welch \n",
    "from sklearn.metrics import accuracy_score,recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b14543-af08-4a83-a944-9099bbf5b5de",
   "metadata": {},
   "source": [
    " ## Import Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2a39c-9bac-40e9-9a4b-51f22aa7a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "file_path = \"C:/Users/katja/Programing_project/Data\" \n",
    "raw_list = []\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    raw = mne.io.read_raw_bdf(os.path.join(file_path,file), preload = True,verbose = False) \n",
    "    raw_list.append(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0046372c-4bf7-469d-821c-849166cc17d1",
   "metadata": {},
   "source": [
    "## Filtering ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da443f45-e84f-4255-aef7-30d85bdc9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering \n",
    "raw_test = raw_list[1]\n",
    "raw_test.plot(start = 0, duration = 30,scalings = dict(eeg=200e-6)) # Sclaed plot of file with index 1 \n",
    "\n",
    "for raw in raw_list: \n",
    "    raw.filter(1.0,40.0, verbose = False) # Bandpass filtering \n",
    "    raw.notch_filter(50.0, verbose = False) # Notch filtering ( 50 Hz european standards, change to 60 Hz in USA)\n",
    "    raw.set_eeg_reference('average', verbose = False) #Rereferencing using average method\n",
    "\n",
    "raw_test.plot(start = 0, duration = 30,scalings = dict(eeg=200e-6)) #Plot after filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847d794-700f-4f56-9358-a43ed221ff08",
   "metadata": {},
   "source": [
    "## Prepare ICA and data for artifact removal ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05918d-bbf9-418a-a842-b0e682f641de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_list = [] #Empty list for ICA components \n",
    "\n",
    "for raw in raw_list:\n",
    "    montage = mne.channels.make_standard_montage('standard_1020') # Give channels positions according to the 10 20 system \n",
    "\n",
    "    # Mark EXG channels as NA \n",
    "    raw.set_channel_types({\n",
    "        'EXG1':'misc', 'EXG2':'misc', 'EXG3':'misc', 'EXG4':'misc',\n",
    "        'EXG5':'misc', 'EXG6':'misc', 'EXG7':'misc', 'EXG8':'misc'\n",
    "    })\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "# Configure and fit ICA to the data\n",
    "for raw in raw_list:\n",
    "    ica = ICA(n_components=15, method='fastica', random_state=42, verbose = False)\n",
    "    ica.fit(raw, verbose = False )\n",
    "    ica_list.append(ica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9882892-b136-46a2-b13c-385223ab9393",
   "metadata": {},
   "source": [
    "## Plot ICA components to identify artifacts ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c055c3c-a5eb-4c43-918e-dbaa7ea68746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates variable  that only include one file\n",
    "raw_test = raw_list[1]\n",
    "ica_test = ica_list[1]\n",
    "\n",
    "# Plot components of one file \n",
    "ica_test.plot_components()\n",
    "\n",
    "# Plot overlay of raw signal with specific ICA components excluded for one file \n",
    "ica_test.plot_overlay(raw_test, exclude=[0])  # exclude component 0 in file idx 1\n",
    "ica_test.plot_overlay(raw_test, exclude=[1])  # exclude component 1 in file idx 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c031fef-6a9f-4853-a1f9-22080f36f2a3",
   "metadata": {},
   "source": [
    "## Apply ICA filtering to remove artifacts ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917acf29-ef6f-4bbf-847b-9bb3964c745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply ICA filtering \n",
    "processed_raw = []\n",
    "\n",
    "#Combine ICA and and the raw datafiles \n",
    "for ica, raw in zip(ica_list, raw_list):\n",
    "    ica.exclude = [0,1] #exclude components \n",
    "\n",
    "    raw_clean = ica.apply(raw.copy(), verbose = False) #Create copies of each raw file xith ica applied \n",
    "    processed_raw.append(raw_clean) # add raw_copies to list\n",
    "\n",
    "# Plot one fiel from the processed list to compare with unfiltered plot\n",
    "raw = processed_raw [1]\n",
    "raw.plot (start = 0, duration = 30, scalings=dict(eeg=200e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef942cf1-0d69-47cb-b6d4-1f79b09cf6bf",
   "metadata": {},
   "source": [
    "## Defining Feature Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db67c57-44c1-4d33-b2cf-e8f5d5917dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Computing shannon entropy \n",
    "def shannon_entropy(signal):\n",
    "    pdf, _ = np.histogram(signal, bins=50, density=True)\n",
    "    pdf = pdf[pdf > 0]\n",
    "    return -np.sum(pdf * np.log2(pdf))\n",
    "\n",
    "#Computing bandpower \n",
    "def compute_bandpowers(signal, sfreq):\n",
    "    freqs, psd = welch(signal, sfreq, nperseg=len(signal))\n",
    "\n",
    "#Defining band frequencies \n",
    "    bands = {\n",
    "        'delta': (0.5, 4),\n",
    "        'theta': (4, 8),\n",
    "        'alpha': (8, 12),\n",
    "        'beta':  (12, 30),\n",
    "        'gamma': (30, 45)\n",
    "    }\n",
    "\n",
    "    bp = {}\n",
    "    for band, (low, high) in bands.items(): #Looping through bands to define frequency range \n",
    "        idx = (freqs >= low) & (freqs <= high) #boolean array indicating if the frequencies in the segment fall inside a specific frequency band \n",
    "        bp[band] = np.trapz(psd[idx], freqs[idx]) # Calculates psd for the frequencies in the specific band and segment \n",
    "    return bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cb95-f487-4214-ae5e-7695e14937f8",
   "metadata": {},
   "source": [
    "## Apply feature extraction ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be78fa5-7f8e-44b3-b4a2-a4b39cd8fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiating empty list for features \n",
    "subject_features = []\n",
    "\n",
    "file_path = \"c:\\\\Users\\\\katja\\\\Programing_project\\\\Data\" #Indicate file path to datafiles \n",
    "\n",
    "files = [file for file in os.listdir(file_path) ] #Iterate over files in file path and save filename in \"files\"\n",
    "\n",
    "# Pair each processed file with its' filename and assign a group and subject based on the file name \n",
    "for raw_clean, file in zip(processed_raw, files):\n",
    "    group = \"healthy\" if \"sub-hc\" in file else 'pd' # if filename contains \"sub-hc\" assign to healthy\n",
    "    subject = file.split('_')[0].replace('sub-','') # Keep everything before _ in file name and remove the \"sub\" letters to get subject\n",
    "    \n",
    "    #Epoch the data \n",
    "    epochs =mne.make_fixed_length_epochs(\n",
    "        raw_clean, \n",
    "        duration = 20, # 20 second epochs \n",
    "        preload = True, # save in RAM to be able to edit files \n",
    "        verbose = False)\n",
    "    \n",
    "    #Extract epochs to data \n",
    "    data = epochs.get_data()\n",
    "\n",
    "    subject_epoch_features =[] #Initiate empry list to keep features before averaging \n",
    "    \n",
    "    for i in range(data.shape[0]): # for epoch in epochs of data \n",
    "        for ch in range (data.shape[1]): # for channels in channels of data\n",
    "            segments = data[i, ch, :] # segment the data extracting one epoch and one channel from that epoch including all its timepoints \n",
    "\n",
    "            # Skip segments which have 0 or NAN as standard deviation \n",
    "            std = np.std(segments)\n",
    "            if std == 0 or np.isnan(std):\n",
    "                continue \n",
    "            else:\n",
    "                segments = (segments - np.mean(segments))/np.std(segments) #Normalize (Z-score)\n",
    "\n",
    "            # Apply features using function \n",
    "            entropy_values = shannon_entropy(segments) \n",
    "            bp_values = compute_bandpowers(segments , raw_clean.info['sfreq'])\n",
    "\n",
    "            #Store the data as a dictionary (except bandpowers)\n",
    "            featured_data = {\n",
    "                \"entropy\" : entropy_values,\n",
    "                \"group\": group,\n",
    "                \"subject\": subject\n",
    "            }\n",
    "\n",
    "            # Store bandpowers in featured_data dictionary \n",
    "            featured_data.update(bp_values)\n",
    "            subject_epoch_features.append(featured_data) # Append dictonary content to the second initiated list \n",
    "\n",
    "    #Create dataframe from list  \n",
    "    df_epochs = pd.DataFrame(subject_epoch_features)\n",
    "\n",
    "    #Average the segmented data per subject \n",
    "    df_mean = df_epochs.groupby(\n",
    "        [\"subject\", \"group\"]).mean(numeric_only = True).reset_index() # indicate to only use numeric data for averaging \n",
    "    \n",
    "    subject_features.append(df_mean) # Append to firstly initiated list \n",
    "\n",
    "# Create final data frame and concatinate to get subject labels on y axis and feature labels on x axis \n",
    "df_subject = pd.concat(subject_features, ignore_index = True)\n",
    "df_subject.to_csv(\"features_new_EEG.csv\", index = False) # Save data frame as CSV \n",
    "print(df_subject) # Investigate the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
